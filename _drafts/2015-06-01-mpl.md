---
title: MPL
layout: post
#commentIssueId: 8
---
In this post I'll explain MPL, the research language I'm working on in the Programming Language Lab at the University of Calgary. It's a concurrent language, which is a bit strange because none of us here have any major experience making concurrent software. Instead, MPL is derived largely from Category Theory, a branch of mathematics that I have so far been unable to understand personally.

As originally conceived, MPL is divided into two separate parts, a "concurrent" part ("processes") and a sequential part ("functions"). The sequential part is not very important--it's basically a pure functional language like Haskell--but it has a couple of interesting concepts so I'll talk about it for awhile.

The original syntax of MPL is very unusual. To make this document easier to follow, I'll use a C++/Java-style syntax instead (and I will assume you know C++, C# or Java). I'll still call it MPL, because the "real" syntax is not stable, not well designed, and not important; it's the internal ideas that matter.

The key properties of MPL
-------------------------

MPL has two key properties:

1. Type-safe concurrency
2. Guaranteed termination

MPL programs consist of a set of "processes" that run concurrently. Conceptually, what we call _processes_ are threads. Much like Erlang, if MPL had a production-quality compiler it would surely support some kind of lightweight processes (e.g. [green threads](http://en.wikipedia.org/wiki/Green_threads) with small stacks), because it would probably not be unusual for MPL programs to consist of hundreds or thousands of processes.

Processes communicate with each other exclusively by passing messages; there is no concept of shared memory, so MPL would easily scale across multiple computers. However, if you happen to be passing large data structures between processes then shared memory could (as an implementation detail) improve performance. MPL "solves" the problem of shared mutable state simply by not allowing mutable variables; the Haskell language already showed this design option to be viable (as suggested by Haskell's mathematical predecesor, a certain variant of the lambda calculus).

**Type-safe concurrency** means that when one process sends an integer, there is always another process that is ready (or will be ready in the future) to receive an integer. When one process sends a string, another is ready to receive a string. And so on. Communication between process is governed by special types called _protocols_. A protocol is a type that explains how communication works between a pair of processes, on a "channel" (a channel is a connection between exactly two processes). Here's a simple example of a protocol, which I'll call a "lookup" protocol:

  1. Put an integer.
  2. Get a string.
  3. Start over.

If one process is following the above protocol, another protocol must be following the complement (or negation) of the protocol:

  1. Get an integer.
  2. Put a string.
  3. Start over.

As an example, imagine a simple "list service" process that contains a large list of strings. It follows the second protocol: it gets an integer (waiting if necessary), and when it gets one, it treats it as an index, looks up the string at that index in the big list, and sends the string back.

There's a couple of things missing though. First, the list service needs to initialize when it starts, so a process can take zero or more so-called "sequential" parameters which must be provided to start the process. Some outside code might provide the list this way. How does one start a process? I'll get to that later.

Second, the dictionary process needs to know when it should shut down. MPL has named protocol "constructors" or "selectors" which represent different "paths" through the protocol. In one of the paths, one of the processes may be required to shut down (the other process keeps running). For example:

  1. Choose either 
     Lookup: Put an integer, get a string, and start over.
     StopLookups: Close the channel.

The complement protocol, implemented by the "list service", is

  1. Receive either
     Lookup: Get an integer, put a string, and start over
     StopLookups: Shut down the current process.

Here's what the protocol might look like in source code (one of many possible choices of syntax):

    protocol StringLookup = put Lookup, put Int, loop 
                          | put StopLookups, close;

In this version of the syntax, "loop" means "start over at the beginning of `StringLookup`". Since there's a "close" on the `StopLookups` branch, the process using the _complement_ of `StringLookup` must halt itself. Note that the two paths (`Lookup` and `StopLookups`) must _both_ start with "put" or _both_ start with "get". It makes no sense otherwise: which process would choose the path to take? And in MPL as originally conceived, the protocol definition is also defining the identifiers `Lookup` and `StopLookups`, and these names must be unique program-wide.

Actually I'm going to talk about "MPL as originally conceived" a lot, so I'll abbreviate that as MPL-AOC.

Q. Can there be another "version" of the complement protocol in which neither process shuts down?
A. In MPL-AOC, no. Whenever a channel closes, one process always shuts down.

Now here's how the list service might look:

    process ListService(neg<StringLookup> channel, string[] data)
    {
      case channel.get of {
        Lookup ->
          let index = channel.get;
          channel.put(data[index, ""]);
          ListService(channel, data);
        StopLookups -> // no-op
      }
    }

MPL-AOC does not support loops; instead a process has to "call" itself instead. It wasn't made clear to me whether this is truly a "call", or actually a "goto", because in all existing examples the call happens at the very end of the process. And if it is a call, I wasn't told whether it's sequential (blocking) or parallel. There was a concept of "plug" for creating new processes; Dr. Cockett recently decided that "plug" would occur implicitly, making it syntactically the same as a call, so I would guess that a "call", like a "plug", is a parallel call.

Of course, you can implement something like protocols in an existing programming language, but the verification that your code follows the protocol would have to happen at run-time. In MPL the program will not compile unless the compiler can tell that your code always follows the protocol.

MPL-AOC has no arrays either, so to understand "string[]" we can either imagine a version of MPL that has arrays, or imagine string[] as some other data structure that MPL-AOC does support, such as a linked list. MPL also has no concept of "exceptions", so the act of getting data from the list cannot fail. I use `data[index, ""]` to mean "get the item at `index`, or an empty string if the index is invalid."

It should be noted that this concept of protocols-on-channels already exists; it's called session types. I was given the impression that the first paper on session types was published at some point before I arrived, _after_ this lab started designing MPL. It looks like the first paper on modern Session Types is "Multiparty Asynchronous Session Types", published in 2008. I'm no mathematician, but it looks to me like session types are isomorphic (equivalent) to MPL's typed protocols.

The second main feature of MPL-AOC is **guaranteed termination**. If you follow certain rules,

1. Sequential code is always guaranteed to terminate (no infinite loops)
2. Concurrent code cannot have deadlocks or livelocks

Thus, the whole program always terminates. Now, I'll talk about sequential MPL for awhile, then resume discussion of the concurrent part.

Sequential MPL
--------------

Roughly speaking, the sequential part of MPL is a simplified version of Haskell with a couple of extra features so that you can write code that is guaranteed to terminate. Unlike Haskell, MPL is not a "lazy"; it runs code immediately like most other programming languages, evaluating a function's arguments _before_ calling the function. The current plan is not to have currying as a core feature either, which meant that continuing to use Haskell-style syntax looks downright strange (different from every other language I've ever seen). Also, closures aren't planned to be plain functions, but are more like Java's anonymous inner classes.

Something called `fold` can verify that a given subprogram will (eventually) terminate. Consider the following MPL code (using a funny mix of C++ and Haskell style):

    data List<t> = Nil                // Empty linked list
                 | Cons(t, List<t>);  // Add an item to the list
    
    fold {
      Int length(fold by List<t> list) {
        case list of {
          Nil -> 0
          Cons(_, rest) -> 1 + length(rest)
        }
      }
    }

Note that in Haskell the equivalent type

    data List t = Nil | Cons t (List t)

could be an infinite list, whereas _this_ data type must be finite (which follows from immutability and the decision not to use lazy evaluation). MPL has a separate category of data types that can be infinite (the "coinductive" ones, see below). Also note that normal data types and "constructors" (`Nil` & `Cons`) must start with a capital letter; the lowercase `t` implies that `t` is a generic parameter, so that (in Haskell lingo) `length` is a polymorphic function. By the way, MPL-AOC has type inference, so you could leave out the type of `list` and the return type of `length`. However, type inference is pedagogically counterproductive, so in this document I'll generally indicate the types of everything explicitly.

The `fold {...}` block is a group of functions that are allowed to call each other recursively (often it's a group of size one). `fold by` tells the compiler that the specified function parameter must be "reduced" during recursion. Here you can see that the list is unwrapped by one level, e.g. `Cons(1, Cons(2, Cons(3, Nil)))` would become `Cons(2, Cons(3, Nil))`. The compiler verifies that this unwrapping occurs, and that the call chain stops at `Nil`, to prove that the function will eventually terminate. And remember, there can be no infinite loops, because loops don't exist.

How exactly is the compiler to verify that the function terminates? Well, we were given a plan based on an idea that I think was called "circular types". I didn't like the plan, though, because it requires exactly one level of unwrapping; for example, it makes the following variation of the function (which unwraps two levels) illegal:

    fold {
      Int length(fold by List<t> list) {
        case list of {
          Nil -> 0
          Cons(_, rest) -> 
            case rest of {
              Nil -> 1
              Cons(_, more) -> 2 + lengh(more)
            }
        }
      }
    }

To complete this example, here's another type and a couple more functions:

    // This type represents zero or one items. It's like "Nullable<T>" in C#.
    data Maybe<t> = Nothing | Just(t)
    
    t unwrap(Maybe<t> value, t defaultValue) {
      case value of {
        Just(x) -> x
        Nothing -> defaultValue
      }
    }
    Maybe<t> head(List<t> list) { // Get first item in list
      case list of {
        Nil -> 0
        Cons(h, _) -> Just(h)
      }
    }
    List<t> tail(List<t> list) {
      case list of {
        Nil -> Nil
        Cons(_, rest) -> rest
      }
    }

By the way, in MPL-AOC, if your function started with `case __ of` you could split up the function into pieces, so the following definitions would be equivalent to the above:

    unwrap(Just x, _) { x }
    unwrap(Nothing, defaultValue) { defaultValue }
    head(Nil)        { Nothing }
    head(Cons(h, _)) { Just(h) }
    tail(Nil)           { Nil }
    tail(Cons(_, rest)) { rest }

`List<t>` is known as an "inductive" data type, meaning its shape is tree-like (acyclic) and always ends; you can't make a linked list that refers back to itself. There is another kind of data type that can appear to go on forever, called the "coinductive" data type. A simple example is the "stream":

    codata Stream<t> {
      Maybe<t> head();
      Stream<t> tail();
    }

A coinductive data type is basically like an interface in Java, but without support for inheritance, and you create such a data type with a "record" keyword which works much like the creation of an anonymous class in Java:

    Stream<Int> intStream(Int start)
    {
      record Stream<Int> {
        Maybe<Int> head() { Just start }
        Stream<Int> tail() { intStream(start + 1) }
      }
    }

Note that the variable `start` is captured from the outer function `intStream()`; since support for ordinary anonymous inner functions is not planned, this is how you make closures in MPL. Terminology note: what normal people would call "methods" or "member functions" are called "destructors" in MPL-AOC. This name reflects a mathematical duality with the "constructors" of coinductive types.

Since everything is immutable in MPL, you can't tell a `Stream` to "advance"; `tail()` must create a new stream object instead. Here are two examples that construct lists out of streams:

    fold {
      // Constructs a linked list in from the given stream. Since a stream 
      // is infinite, `count` specifies the size of the output list.
      List<t> streamToList(Stream<t> s, fold by Int count) {
        if (count <= 0)
          Nil
        else
          Cons(s.head(), streamToList(s, count-1))
      }
    }
    fold {
      // Constructs a linked list in reverse order from the given stream. 
      List<t> reverseStream(Stream<t> s, fold by Int count) {
        reverseStreamImpl(s, count, Nil);
      }
      List<t> reverseStreamImpl(Stream<t> s, fold by Int count, List<t> list) {
        if (count <= 0) 
          list
        else
          reverseStreamImpl(s.tail(), count - 1, Cons(s.head(), list))
      }
    }

I'm cheating a little here by assuming you can "fold by Int", MPL-AOC had no such feature (perhaps it didn't have integers at all). Because of `fold by Int`, the compiler ought to give an error if I wrote `if (count == 0)` instead of `if (count <= 0)` (if it said `count == 0`, `count = -1` would cause infinite recursion.)

MPL-AOC did have type inference so you could leave out the data types. But in MPL-AOC, `head()` and `tail()` were defined in the global namespace, not called using the dot notation. I don't like that because it implies that no other `head` or `tail` function can exist in the program (a serious annoyance of Haskell's record types), given that (as in Haskell) function overloading is not supported.

You can convert a `List<t>` into a `Stream<t>`:

    Stream<t> toStream(List<t> list)
    {
      record Stream<t> {
        // this code calls head() and tail() as defined earlier
        Maybe<t> head() { head(list) }
        Stream<t> tail() { toStream(tail(list)) }
      }
    }

But since the compiler can prove termination only with inductive data, it's preferred to use inductive data where possible. Note that there's no such thing as a "class"; you must use `record` inside a function to construct coinductive data.

If you need to simulate a data structure that contains a cycle, you could use `codata` that refers to some other `data` or `codata`. For example, this code constructs a cyclic stream from a linked list:

    Stream<t> toCyclicStream(List<t> list) { toCyclicStream'(list, list); }
    Stream<t> toCyclicStream'(List<t> ptr, List<t> list) {
      record Stream<t> {
        Maybe<t> head() { head(ptr) }
        Stream<t> tail() {
          case list of {
            Nil          -> toCyclicStream'(list, list)
            Cons(x,rest) -> toCyclicStream'(rest, list)
          }
        }
      }
    }

Often there is an equivalence between inductive and coinductive data. For instance we can represent a "pair" of things in either form:

    // Inductive: "destructors" (first & second) must be defined manually
    data Pair<a,b> = Pair(a, b)
    first(Pair(x,y)) { x }
    second(Pair(x,y)) { y }
    
    // Coinductive: "constructor" (mk_pair) must be defined manually
    codata Pair<a,b> { a first(); b second(); }
    Pair<a,b> mk_pair(a itemA, b itemB) {
      record Pair<a,b> {
        first() { itemA }
        second() { itemB }
      }
    }

Concurrent MPL: Hello World & terminal output
---------------------------------------------

It's natural to ask how can we write "Hello, World!" on the screen... even if MPL's designer never thought of it until I came along.

Actually, this is a nontrivial question to _choose_ the answer for because MPL has no global variables or mutable state. The "sequential" part of MPL-AOC has no side effects or anything resembling them, but the concurrent part does at least have "channels", and it is natural that the terminal be represented by some kind of channel.

There are different ways that a terminal API could work, and it's not really obvious which to choose. First of all, can we have multiple terminals? Well, we want MPL to be able to run on multiple computers, but we're very early in development and in any case, it seems like there should be a "default" terminal, the one connected to `stdin` and `stdout` or at least, the same terminal that was used to start the program.

And since channels are bidirectional, should the input and output be bundled together as a single channel, or split into two separate channels? You might say "well, we should bundle them: we can't read a line of input and write a line at the same time. We need bundling to enforce an ordering between reads and writes". However, terminals actually _can_ do that, even if it makes the terminal looks and act clumsily. Another issue is that `stdout` is capable to writing single characters, but `stdin` is (on some platforms anyway) limited to reading entire lines at once. But I guess we could ignore that for the purpose of this decision.

So let's say we have a character-based terminal. Possible protocols include...

  // Predefined (`GetSeq<Char>` for an input terminal)
  protocol GetSeq<t> = put Get, get t, loop
                     | put StopGet, close
  // Predefined (`PutSeq<Char>` for an output terminal)
  protocol PutSeq<t> = put Put, put t, loop
                     | put StopPut, close
  // Predefined (`BidiSeq<Char>` for a bidirectional terminal)
  protocol BidiSeq<t> = put Get1, get t, loop
                      | put Put1, put t, loop
                      | put StopBidi, close

Of course, it occurs to me that requiring tags like `Get` and `Get1` to be unique program-wide is going to get annoying fast, especially the `Stop` commands (which are already annoying just by being included explicitly). Personally, I'm wondering if a union type system is the answer...

Anyway, if there _are_ two separate channels, we can combine them:

  process makeBidi(neg<BidiSeq<t>> combined, GetSeq<t> getc, PutSeq<t> putc)
  {
    case combined.get of {
      Get1     -> getc.put(Get); combined.put(getc.get);
      Put1     -> putc.put(Put); putc.put(combined.get);
      StopBidi -> getc.put(StopGet); putc.put(StopPut);  halt;
    }
    makeBidi(combined, getc, putc);
  }

However, given a bidirectional channel, it's _not generally possible to separate them_. We'll see why later, but my conclusion is that it's better to provide separate terminal input and output channels. That said, Jonathan picked a combined design.

Obviously, MPL isn't the kind of language where you can actually _implement_ access to a terminal; if MPL is built as a standalone language, the terminal channels must be provided from outside the program, and for simplicity we'll probably make them built-in.

So again, how do we write "Hello, World"?

At the outer level of the program (outside any process) there is a mechanism to run a group of processes; at this level, the terminal channels can each be predefined, with one endpoint pre-established. You can start multiple processes, but the compiler will verify that each terminal process is used only once. Let's suppose the name of our terminal is `stdin` and `stdout` (of course, they may be files rather than terminals, which is fine). The current plan is that `stdin` and `stdout` can only be mentioned at the top level, so we could write "Hello, World!" as

    // In MPL-AOC you'd surround the next two lines in a "run" block.
    makeBidi(~console, stdin, stdout);
    writeHello(console);

    process writeHello(BidiSeq<Char> console)
    {
      console.put(Put1); console.put('H');
      console.put(Put1); console.put('e');
      console.put(Put1); console.put('l');
      console.put(Put1); console.put('l');
      console.put(Put1); console.put('o');
      // 7 more lines of code
      console.close();
    }

This is horrifying, but can be improved with helper process(es). The identifier `console` wasn't defined anywhere; I have the impression that Dr. Cockett's new plan is to allow new channels to be created implicitly, by creating a channel whenever an undefined identifier is used in exactly two places in a series of wiring (i.e. process-start) commands. Here, the notation `~console` means "the negation (complement) of the protocol of console". Either side of the channel could be negated:

    makeBidi(console, stdin, stdout);
    writeHello(~console);

In fact, MPL-AOC doesn't use complements; instead there is a concept of "polarity": left and right. In that design, a channel must always be connected to the "right" side of one process and to the "left" side of another process; in this case, "negation" is never necessary (at least in theory). In fact, the _current_ MPL design also includes polarity, and hey, won't my labmates be surprised to see that I'm talking about an MPL without polarity! I believe that MPL with polarities is equivalent to MPL without polarities, and there's only one reason I've described MPL without polarities here: clarity. Most programmers are familiar with C++/C#/Java syntax, and Dr. Cockett's current syntax is potentially confusing, especially the signature (header). It looks like this:

    process bulkPutAdapter :: PutSeq(|[t]) =>> PutSeq(|t) | [t] ::=
      client =>> putseq = putInitially ->>
        case putInitially of 
          [] ->> 
            handle client as
              get buf on client
              Put ->> bulkPutAdapter(client =>> putseq | buf)
              StopPut ->> put StopPut on putseq
                          close putseq
                          end client
          c:rest ->
            put Put on putseq
            put c on putseq
            bulkPutAdapter(client =>> putseq | rest);

I simply think beginners will be more comfortable with an ordinary argument list.

Let's assume that a `String` is a linked list of characters using Haskell notation (`[Char]`, `head:tail`). Then the following is a "write string" adapter (but generalized, so I call it `bulkPutAdapter`):

    process bulkPutAdapter(neg<PutSeq<[t]>> client, PutSeq<t> putseq, [t] putInitially) 
    {
      case putInitially of {
        [] -> 
          case client.get of {
            Put -> bulkPutAdapter(client, putseq, client.get);
            StopPut -> putseq.put(StopPut); halt;
          }
        c:rest ->
          putseq.put(Put);
          putseq.put(c);
          bulkPutAdapter(client, putseq, rest);
      }
    }

Now we can write "Hello, World" as

    bulkPutAdapter(~strOut, stdout, "");
    writeHello(strOut);
    
    process writeHello(PutSeq<[Char]> strOut)
    {
      strOut.put(Put);
      strOut.put("Hello, world!\n");
    }

Concurrent MPL: The guessing game & terminal input
--------------------------------------------------

Now let's suppose we want to play a guessing game, something that is easy in a sequential imperative language. The game is "I'm thinking of a number between 1 and 100. Guess it!" For that we'll need a way to "read a line" from the console. Here's a process for that (but generalized, so I call it `bulkGetAdapter`). It's more complicated than `bulkPutAdapter` because it watches for a delimiter at which to split the input sequence.

    process bulkGetAdapter(neg<GetSeq<[t]>> client, GetSeq<t> getter, t delimiter)
    {
      case client.get of {
        Get -> bulkGet(client, getter, delimiter, []);
        StopGet -> getter.put(StopGet); halt;
      }
    }
    protocol GetThen<t,p> = get t, p
    process bulkGet(neg<GetThen<[t],GetSeq<[t]>>> client, 
      GetSeq<t> getter, t delimiter, [t] buf)
    {
      getter.put(Get);
      let c = getter.get;
      // I'm cheating: we haven't planned a general equality operator yet
      if (c == delimiter) {
        client.put(buf);
        bulkGetAdapter(client, getter, delimiter, buf);
      } else {
        bulkGet(client, getter, delimiter, c:buf);
      }
    }

Remember that `GetSeq<t>` is defined as `put Get, get t, loop | ...`. `bulkGet` is called after `client.get`, which means we're somewhere in the middle of protocol `GetSeq<[t]>`,  This means the first parameter of `bulkGet` cannot have type `neg<GetSeq<[t]>>`, because that type represents the _beginning_ of the protocol.

Specifically, when `bulkGet` is called, the protocol is at the `get t, loop` part of `GetSeq<[t]>`, i.e. `get [t], GetSeq<[t]>` in this context. How do we represent the "middle" of the protocol? Well, I've defined a protocol `GetThen<t,p>` as `get t, p`. Therefore, `neg<GetThen<[t],GetSeq<[t]>>>` means `put [t], neg<GetSeq<[t]>>`. Sure enough, `bulkGet` puts one `[t]` into `client` and then calls `bulkGetAdapter` with the protocol which has become a `neg<GetSeq<[t]>>`. Whew. At least MPL-AOC has type inference.

You may wonder, does this code _have_ to be written as two separate processes? I'm afraid so, since there are no loops in MPL-AOC and it does not even allow you to pass a channel to an ordinary function.

Next, where can we get a random number? There are no true globals, but let's suppose there is an outside `timeService` that provides a high-precision CPU timer. In this case the language restriction of having only a single process talking to it is onerous, and I think we should revise that plan. Anyway, the low bits of a microsecond timer will seem random enough. Here's my guessing game implementation.

    // predefined
    protocol TimeService = put GetCpuTimerMicroseconds, get Int, loop
                         | // other time services here
                         | put StopTimeService, close

    // prelude
    Int strToInt(String s) {...}
    String concat(String s1, String s2) {...}
    t unwrap(Maybe<t> value, t defaultValue) {...}

    // wiring
    guessingGame(timeService, console);
    makeBidi(~console, strIn, strOut);
    bulkPutAdapter(~strOut, stdout, "");
    bulkGetAdapter(~strIn, stdin, '\n');
    
    process guessingGame(TimeService time, BidiSeq<Char> console)
    {
      time.put(GetCpuTimerMicroseconds);
      let num = time.get % 100 + 1;
      console.put(Put1);
      console.put("I'm thinking of a number between 1 and 100. Guess it!\n");
      time.close();
      guessingGame2(num, console);
    }
    process guessingGame2(Int num, BidiSeq<Char> console)
    {
      console.put(Get1);
      let guess = strToInt(console.get).unwrap(-1);
      if (guess != num) {
        if (guess < num) {
          console.put(Put1);
          console.put("Too low! Guess again!\n");
        } else {
          console.put(Put1);
          console.put("Too high! Guess again!\n");
        }
        guessingGame2(num, console);
      } else {
        console.put(Put1);
        console.put(concat(concat("Right on! I was thinking of ", num), "!\n");
        console.close();
      }
    }

It's pretty annoying that I have to do two `put` commands to print a single line of text. The language could improve this a little by supporting chaining, as in 

    console.put(Put1).put("Too high! Guess again!\n");

But it's clear that such calls will be pervasive in MPL, and therefore a nicer syntax is desirable, maybe something like

    console.Put1("Too high! Guess again!\n");

But for now, I'll settle for chaining. I also see no reason why I would have to close a console explicitly, or halt explicitly; these are not my ideas, and I'm not quite sure what the rules are supposed to be about them.

Concurrent MPL: split, fork, plug
---------------------------------

In many of these examples we've "called" from one process to another. Conceptually, the new process runs in parallel with the current one, but if calling a process is the last act of a process, the new process can obviously continue on the same thread, as the old process disappears.

Though I needed some months to figure out the meaning of 'fork' and 'split', their meaning turned out to be quite simple. Given two processes with a channel between them (plus some extra channels `a b c`, attached to P0 with dotted lines),

         +--------+         +-------+
    a....|        |         |       |
    b....|   P0   |---------|   Q   |
    c....|        |  qlink  |       |
         +--------+         +-------+

`fork` is a command that splits the current process (P0, here) into two new processes while terminating the current process:

           (fork)            (split)
         +--------+         +-------+
    a....|   P1   |---------|       |
         +--------+  qlink1 |       |
                            |   Q   |
         +--------+         |       |
    b....|   P2   |---------|       |
    c....|        |  qlink2 |       |
         +--------+         +-------+

The other process uses `split`, which means "I expect this channel to change into two channels." The protocol of `qlink` must also say "there's going to be a split". Here, letters `a b c` represent three existing channels. P0 can distribute these channels to `P1` and `P2` in any way it chooses. MPL-AOC seems to have a concept of "inner processes" (closures) for the sole purpose of forking:

    process P0(ProtocolA a, ProtocolB b, ProtocolC c, ProtocolQ qlink, Int num)
    {
      qlink.put(Q).put(12345);
      fork qlink as                   // simplified syntax compared to MPL-AOC
        qlink1 { /* P1 */ a := qlink1; },
        qlink2 { /* P2 */ P2(b, c, qlink2, num); };
      // P0 ends; no additional code is allowed down here
    }
    process Q(neg<ProtocolQ> qlink)
    {
       case qlink.get of {
         Q ->
           Int num = qlink.get;
           split(qlink) as (qlink1, qlink2);
           // qlink no longer exists at this point
           ...
       }
    }

If two channels have complement protocols (or the same protocol with opposite polarity), you can simply join them with `:=` as you see here (MPL-AOC used `==` to mean the same thing.)

Protocol Q might look like something like this:

    protocol ProtocolQ = put Q, put Int, fork (neg<ProtocolA>, ProtocolQ2)
                       | ...

The other primitive for creating processes was called "plug" in MPL-AOC, but the new plan seems to be to make process creation implicit. You simply "call" two or more processes, which then become separate entities from the current process:

    process P0(ProtocolA a, ProtocolB b, ProtocolC c)
    {
      P1(a, link);
      P2(b, ~link);
      // there can be additional code down here
    }

    Before:
    +--------+
    |        |....a
    |   P0   |....b
    |        |....c
    +--------+

    After:
    +--------+          +------+....a       +------+
    |        |          |      |            |      |
    |   P0   |          |  P1  |------------|  P2  |....b
    |        |....c     |      |    link    |      |
    +--------+          +------+            +------+

The channel `link` is created implicitly by being mentioned exactly twice. 

Exactly two processes have access to any given channel, so when `P0` passes `a` to `P1`, it loses access to `a`. Curiously, I've gotten a strong impression that the processes P1 and P2 are completely separate, and have no ability to communicate with P0 (not even indirectly, as we'll see later). A more sensible plan, it seems to me, would be to allow developers to create a channel which you can then use inside P0, something like this:

    process P0(ProtocolA a, ProtocolB b, ProtocolC c)
    {
      channel p0link, link;
      P1(a, link, p0link);
      P2(b, ~link);
      // there can be additional code down here
    }

    +--------+          +------+....a       +------+
    |        |  p0link  |      |            |      |
    |   P0   |----------|  P1  |------------|  P2  |....b
    |        |....c     |      |    link    |      |
    +--------+          +------+            +------+

It wasn't clearly stated whether you could create more than two processes at once, but I think you should be able to wire up a process graph of arbitrary size this way, as long as its shape is specified statically (i.e. in a series of source code statements, not computed).

Note that a channel must connect two processes. The two sides of a channel cannot be given to the same process.

Concurrent MPL: deadlock avoidance
----------------------------------

A deadlock is a situation in which two or more competing actions are each waiting for the other to finish. For example, process A is waiting for B to do something, B is waiting for C to do something, and C is waiting for A. In other words deadlocks always involve a _cycle_. The way that MPL proposes to avoid deadlocks is simple: no cycles are permitted.

This is enforced by construction. Suppose that we start with an (undirected) process graph with no cycles:

      P0---P2   P5------P7
        \      /  \      |
         \    /    \     P8
          \  /      \    
      P3---P1---P4   P6

Also, suppose that the compiler verifies that when you create a new set of processes (the mechanism formerly known as 'plug') there are no cycles, you do not connect two processes with more than one channel, and you do not give both ends of a channel to the same process. This is easy for the compiler to check. In case you're clever enough to think about aliasing, I would point out that MPL won't allow channel aliasing. All channel references are unique, a restriction that also makes it straightforward for the compiler to verify that the channel's protocol is being followed.

Clearly, any of the processes in this graph (or any other acyclic graph) is attached to one or more _independent_ subtrees. For example, P5:

                   +----+
      P1(etc.)-----| P5 |-----P7(etc.)
                   +----+\
                          \---P6

Clearly, P5 represents the only link, direct or indirect, between P1 and P7, P6 and P7, and between P1 and P6. If there is only a single channel connecting each pair of processes, and the whole graph is acyclic, there can be no cycle of waiting, so there can be no deadlocks. For example, if P5 is waiting for another process, say P7, there's no way P7 can also be waiting for P5. Remember that the protocol type system verifies that along a single channel, a `get` in one process is matched up with a `put` in the other, and there's only one channel between P5 and P7. QED.

Knowing that any acyclic graph is deadlock-free, we just have to check that the two primitives given above for creating new processes (fork/split and the process-creation primitive formerly known as 'plug') do not create cycles. When creating a new set of processes, the compiler simply needs to check that there are no cycles in the new subgraph. Likewise it is straightforward to convince oneself with diagrams that fork/split cannot create a cycle, although I don't want to bother drawing more diagrams here (it's kind of tedious.)

I fully expect that if someone with a lot of experience in concurrent programming is reading this, they might be saying "duh, I knew that", and yet they may still have trouble with deadlocks in their large systems. Sometimes this is due to programming mistakes or design flaws, something that a strong type-checker like MPL's would help with, but I suspect that at other times, the design might intentionally use cycles for good reasons that I am unaware of (for example, having _no_ cycles seems to guarantee a single point of failure). For that reason, I guess, Dr. Cockett is proposing some sort of weaker compiler mode that won't ensure there are no deadlocks, but in that case it isn't clear whether MPL has advantages over session types (which are already described in the academic literature). I don't think anyone here has investigated the properties of the plug/fork primitives in a cyclic environment.

Concurrent MPL: sending channels as alternate to fork/split
-----------------------------------------------------------

In MPL-AOC, you are extremely limited in what you can do with channels. You cannot store channels in data structures, you cannot pass a channel to "sequential" function, and you cannot send a channel along another channel to an existing process. Thus, it achieves its goals at a very high cost.

I find the fork/split primitive to be an awkward thing. Instead I would propose allowing sending channels along other channels. It provides more flexibility, is simpler for the compiler (no "inner process", no "fork/split" primitive, nothing extra in the protocol types), and provides the same guarantee: it cannot create cycles. Let's "split" P0 like in the earlier example, but without actually terminating P0 as split requires:

    Before:
         +--------+         +-------+
    a....|        |         |       |
    b....|   P0   |---------|   Q   |
    c....|        |  qlink  |       |
         +--------+         +-------+

    After:
           (fork)            (split)
         +--------+         +-------+
    a....|   P0   |---------|       |
         +--------+  qlink  |       |
                            |   Q   |
         +--------+         |       |
    b....|   P2   |---------|       |
    c....|        |  qlink2 |       |
         +--------+         +-------+

    protocol ProtocolQ = put Q, put Int, put ProtocolQ2, neg<ProtocolA>
                       | ...

    process P0(ProtocolA a, ProtocolB b, ProtocolC c, ProtocolQ qlink, Int num)
    {
      qlink.put(Q).put(12345);
      neg<ProtocolA> qlink2;
      P2(b, c, qlink2, num);
      qlink.put(qlink2);
      a := qlink1;
    }
    process Q(neg<ProtocolQ> qlink)
    {
       case qlink.get of {
         Q ->
           Int num = qlink.get;
           ProtocolQ2 qlink2 = qlink.get;
           ...
       }
    }

I also see no reason not to allow channels to be sent to (sequential) functions. Functions receiving channels won't exactly be "purely functional", but that's fine with me, and in terms of compiler complexity I don't see a major change.

The other big limitation of channels is that you can't store them in data structures. Allowing this is very tricky since it implies aliasing, but the problem is already well-researched; just read about typestate, such as you'd find in [Plaid](http://www.cs.cmu.edu/~aldrich/plaid/). Even without typestate, I'm fairly confident that MPL-like channels are doable in [Rust](http://www.rust-lang.org/), including storing them in data structures.

Concurrent MPL: recursive protocols & sequential proceses
---------------------------------------------------------

In the next example I want to write a TCP server, so that means I'll need predefined MPL protocols for TCP. The following protocols are inadequate for real-world usage, but for experimental purposes I guess they will suffice.

  // When you listen for connections in a loop, you get a sequence of connections.
  // If, for simplicity, we accept all connections and never time out, we could say
  // we're getting a sequence of byte streams (each by stream being bidirectional).
  protocol BoundTcpServer = GetSeq<BidiSeq<Byte>>;
  // Note: MPL-AOC does not support anonymous choice `( ... | ... )`, seen here
  protocol TcpServer = put ListenOnPort, put Int, 
      ( get TcpBindSuccess, BoundTcpServer 
      | get TcpBindFailed, loop );

Three or four weeks ago, while still trying to figure out MPL, I asked Dr. Cockett if he could give me an example of a nontrivial protocol composed from at least one other protocol. He did not answer my question, so it still isn't quite clear to me how protocol composition works. Here, I've assumed that when `BoundTcpServer` is used inside `TcpServer` it's a "goto" command rather than a "call". This interpretation would mean that I need not (and cannot) have anything after `BoundTcpServer` in the protocol. It would suggest that the following protocol is not possible:

    // Put a certain number of 't' values, then get an equal number back
    protocol GetsAndPuts<t>  = GetsAndPuts2<t>, close;
    protocol GetsAndPuts2<t> = get GetT, get t, GetsAndPuts2<t>, put t;
                             | get StopGetT;

But wait, hold on. On second thought, could polymorphism rescue us, assuming protocols are allowed as generic parameters?

    protocol PutThen<t,p> = put t, p
    protocol GetsAndPuts<t> = GetsAndPuts2<t, close>;
    protocol GetsAndPuts2<t, p> = get GetT, get t, GetsAndPuts2<t, PutThen<t, p>>;
                                | get StopGetT, p;

Holy crap, I think it'll work! It's unintuitive, but ... yeah. It seems to make sense, let's see...

Actually, in MPL-AOC I don't think it's allowed to have a 'bare' protocol like `PutThen` that doesn't start with a choice label (like `(get Label1 | get Label2)`), but then again, in MPL-AOC there was actually _no comma operator_ in protocols; instead, the primitive `get` took the next action after itself as a polymorphic parameter. That is to say, instead of `put a, get b, close` you'd write `Get<a, Put<b, Top>>` or some such, but with different syntax. Thus `PutThen<t,p>` is the same thing as the primitive `Put` command in MPL-AOC. I suppose we can get rid of `PutThen` from this protocol, too, by writing it like this instead:

    protocol GetsAndPuts<t> = GetsAndPuts2<t, close>;
    protocol GetsAndPuts2<t, p> = get GetT, get t, GetsAndPuts2<t, (put t, p)>;
                                | get StopGetT, p;

Let's try using this protocol in a process. Here's a service that buffers up the things put in by some other process, then sends them back.

    // first-in, last-out buffer
    process FiloBuffer(neg<PutsAndGets<t, p>> channel, [t] list) {
      case channel.get of {
        PutT -> let next = channel.get;
                FiloBuffer(channel, next : list);
        StopPutT -> 
                er... what now????
      }
    }

Uh-oh. The problem here is that after `StopPutT` comes `p`, but `p` could be anything: we don't know how to fulfill the protocol. It would be nice if we could simply "return" to whatever process called `FiloBuffer` and let _them_ fulfill the protocol, but I have the impression that processes are always started in parallel (meaning that _there is no call stack_ of processes). If there were a `call` keyword, to call a process sequentially on a call stack, then we could write `FiloBuffer` something like this:

    process FiloBuffer(neg<PutsAndGets<t, p>> channel) {
      case channel.get of {
        PutT -> t next = channel.get;
                call FiloBuffer(channel);
                channel.put(next);
        StopPutT -> // do nothing
      }
      return;
    }

This would work. Assuming the compiler is sophisticated to do the type analysis on this, it would be able to tell when `FiloBuffer` returns, the channel is left in state `(put t, p)` and so it is legal to `put t` at this point, leaving the channel in state `p` on both branches of the `case` statement.

`call` would have limited use, it seems, because processes have no return value. There is no mutable state and it's illegal for a thread to attach both ends of a channel to itself; it's not _quite_ impossible for the called process to return information to its caller, but the information would have to pass through a parallel process. In this example, happily, `FiloBuffer` doesn't need to return anything to its caller, but of course that's not true in general.

We could solve this problem by abolishing the call stack once again but introducing some kind of process closure (essentially, what's known as [continuation passing style](http://en.wikipedia.org/wiki/Continuation-passing_style)). But CPS is clunky, and supporting process closures could add more compiler complexity than my preferred solution.

Let's reconsider our `bulkGetAdapter` from earlier, which we used to read lines from the terminal:

    process bulkGetAdapter(neg<GetSeq<[t]>> client, GetSeq<t> getter, t delimiter) {...}
    protocol GetThen<t,p> = get t, p
    process bulkGet(neg<GetThen<[t],GetSeq<[t]>>> client, 
                    GetSeq<t> getter, t delimiter, [t] buf) {...}

There are a couple of odd things about it:

1. `bulkGet`'s responsibiliy is to get a list of `t`s and send them to the `client`. Because processes have no call stack, it calls `bulkGetAdapter` at the end as a way of "returning" to its caller. This implies that _no other process can call `bulkGet`_ since `bulkGet` "returns" to the wrong place.
2. `bulkGetAdapter` is a separate process from the process that is requesting a line from the terminal, so potentially it runs on its own thread. In a way this is good; if a process `main` wants to read a line from the terminal, it could do some background work while it is waiting. However, 99% of the time `main` really just wants to sit and wait for the input to arrive. Potentially, two threads could be idling, both waiting for a third (the external terminal process) to receive keyboard input. That seems wasteful.

My preferred solution is to _unify_ the sequential and parallel parts of MPL by allowing functions to accept channels. In that case we don't necessarily need `bulkGetAdapter` at all, just `bulkGet`, and the code is simpler.

    [t] readLine(GetSeq<Char> getter) { bulkGet(getter, '\n', []); }
    [t] bulkGet(GetSeq<t> getter, t delimiter, [t] buf)
    {
      getter.put(Get);
      let c = getter.get;
      if (c == delimiter)
        buf
      else
        bulkGet(getter, delimiter, c:buf)
    }

For good measure I've thrown in a bonus `readLine` function. Let's do the same thing with `bulkPutAdapter`, renaming it simply `bulkPut`:

    void writeLine(PutSeq<Char> putseq, [Char] text)
    {
      bulkPut(putseq, text);
      putseq.put(Put).put('\n');
    } 
    void bulkPut(PutSeq<t> putseq, [t] thingsToPut) 
    {
      case thingsToPut of {
        c:rest -> putseq.put(Put).put(c);
                  bulkPut(putseq, rest);
        [] -> // do nothing
      }
    }

We can still define adapters as separate processes if we want; for instance here's the `bulkPutAdapter` reprogrammed to use `bulkPut`:

    process bulkPutAdapter(neg<PutSeq<[t]>> client, PutSeq<t> putseq, [t] putInitially) 
    {
      bulkPut(putseq, putInitially);
      case client.get of {
        Put -> bulkPutAdapter(client, putseq, client.get);
        StopPut -> putseq.put(StopPut); halt;
      }
    }

To complete this idea, let's rewrite `guessingGame` to use this new paradigm:

    guessingGame(timeService, stdin, stdout);
    
    process guessingGame(TimeService time, GetSeq<Char> input, PutSeq<Char> output)
    {
      time.put(GetCpuTimerMicroseconds);
      let num = time.get % 100 + 1;
      
      writeLine(output, "I'm thinking of a number between 1 and 100. Guess it!\n");
      time.close();
      guessingGame2(num, input, output);
      input.close();
      output.close();
    }
    void guessingGame2(Int num, GetSeq<Char> input, PutSeq<Char> output)
    {
      let guess = strToInt(readLine(input)).unwrap(-1);
      if (guess != num) {
        if (guess < num) {
          writeLine(output, "Too low! Guess again!");
        } else {
          writeLine(output, "Too high! Guess again!");
        }
        guessingGame2(num, input, output);
      } else {
        writeLine(output, concat(concat("Right on! I was thinking of ", num), "!\n"));
      }
    }

Notice that the program is a slightly simpler now, apart from the fact that `stdin` and `stdout` are no longer bundled together. Remember, our type system doesn't allow us to put channels in data structures such as `Pair<a,b>`, though perhaps we could make an exception for a built-in tuple type.

Concurrent MPL: file server
---------------------------

Let's try to work out how to implement a TCP parallel file server in MPL (allowing the new features I've proposed). For this we'll need access to the file system and to TCP sockets, perhaps with protocols like these:

  // When you listen for connections in a loop, you get a sequence of connections.
  // If, for simplicity, we accept all connections and never time out, we could say
  // we're getting a sequence of byte streams (each by stream being bidirectional).
  protocol BoundTcpServer = GetSeq<BidiSeq<Byte>>;
  // Note: MPL-AOC does not support anonymous choice `( ... | ... )`, seen here
  protocol TcpServer = put ListenOnPort, put Int, 
      ( get TcpBindSuccess, BoundTcpServer 
      | get TcpBindFailed, loop );

  data Error = Error String;
  protocol PEither<left,rite> = put PLeft, put left,
                              | put PRight, put rite;
  protocol FileSystem = put ReadFile,    put String, get PEither<Error, GetSeq<Byte>>, loop
                      | ...
                      | put StopFileSystem;

  protocol GetSeq<t> = put Get, get t, loop
                     | put StopGet, close
  // Predefined (`PutSeq<Char>` for an output terminal)
  protocol PutSeq<t> = put Put, put t, loop
                     | put StopPut, close


Of course, you can't really understand MPL without seeing how to create multiple processes and dynamically change the network of processes.

Let's start with something simple: a bitmap filter. A bitmap filter is 

- (((can protocols be recursive?)))
- Protocols/coprotocols
- Fork/split
- Sending channels along channels

MPL-AOC


What's wrong with MPL
---------------------

Vague definition

It wasn't made clear to me whether this is truly a "call", or actually a "goto"

Excessive simplicity.

"Everything should be as simple as it can be, but not simpler"

Lack of exceptions

No external shutdown signal

Close vs Halt?

UNTRUE: I don't know about you, but I see a "code smell" here. `bulkGet`'s only responsibility is to get items from `getter` until a delimiter is reached. It does not use `client` at all, except to call `bulkGetAdapter` when it's done. So why does `bulkGet` have to call `bulkGetAdapter` at the end? Well, there's no return stack

